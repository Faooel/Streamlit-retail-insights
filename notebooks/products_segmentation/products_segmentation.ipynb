{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bcee33",
   "metadata": {},
   "source": [
    "# Customer and Product Segmentation\n",
    "## Introduction\n",
    "\n",
    "Customer segmentation has been completed; the resulting output file is: rfm_customer_segments.csv\n",
    "\n",
    "Prerequisite: Create a \"final\" folder in the root directory where the segmentation processing .py file is located.\n",
    "\n",
    "The objective is to extract the segments into a CSV file along with the top 10 products that appear most frequently in the segmented customers' baskets.\n",
    "\n",
    "To achieve this, I will perform data merges across the various input files.\n",
    "\n",
    "Input:\n",
    "- csv/products.csv  \n",
    "- csv/orders.csv  \n",
    "- csv/order_products_prior.csv  \n",
    "- rfm_customer_segments.csv  \n",
    "\n",
    "Output:\n",
    "\n",
    "- final/products_segment.csv: Will contain two columns (segment, products). The products will be ranked in order of importance (purchase frequency).\n",
    "\n",
    "Constraints:\n",
    "\n",
    "- The rfm_customer_segment file contains over 200,000 rows.\n",
    "- The order_products_prior file contains over 32,000,000 rows.\n",
    "- The orders file contains over 3,000,000 rows.\n",
    "- The products file contains over 49,000 rows.\n",
    "\n",
    "Instead of loading all columns from every file, the script will only read the strictly necessary columns. This is crucial to optimize memory usage and prevent out-of-memory errors.  \n",
    "\n",
    "ID Linkages (Merges):\n",
    "\n",
    "- In the rfm_customer_segments and orders files, we use the shared column: user_id\n",
    "- In the orders and order_products_prior files, we use the shared column: order_id\n",
    "- In the order_products_prior and products files, we use the shared column: product_id\n",
    "- Finally, in the products file, we retrieve the column: product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f1caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc # Garbage Collector : pour libérer la RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1912a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION DES CHEMINS ---\n",
    "FILE_RFM = \"csv/rfm_customer_segments.csv\"\n",
    "FILE_ORDERS = \"csv/orders.csv\"\n",
    "FILE_ORDER_PRODUCTS = \"csv/order_products_prior.csv\"\n",
    "FILE_PRODUCTS = \"csv/products.csv\"\n",
    "FILE_OUTPUT = \"final/products_segment.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e483801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Étape 1 : Chargement ciblé des données.\n",
    "    On ne lit que les colonnes nécessaires pour économiser la RAM.\n",
    "    \"\"\"\n",
    "    print(\"1. Chargement des fichiers.\")\n",
    "    \n",
    "    rfm = pd.read_csv(FILE_RFM, usecols=['user_id', 'segment'])\n",
    "    orders = pd.read_csv(FILE_ORDERS, usecols=['order_id', 'user_id'])\n",
    "    \n",
    "    # Ce fichier est énorme (32M lignes), il faut préciser le type de données (int32).\n",
    "    order_products = pd.read_csv(FILE_ORDER_PRODUCTS, usecols=['order_id', 'product_id'], dtype={'order_id': 'int32', 'product_id': 'int32'})\n",
    "    \n",
    "    products = pd.read_csv(FILE_PRODUCTS, usecols=['product_id', 'product_name'])\n",
    "    \n",
    "    return rfm, orders, order_products, products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1cffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(rfm, orders, order_products, products):\n",
    "    \"\"\"\n",
    "    Étape 2 : Jointures successives (Merges).\n",
    "    On supprime les tableaux intermédiaires au fur et à mesure pour ne pas saturer la RAM.\n",
    "    \"\"\"\n",
    "    print(\"2. Début des liaisons (Merges)...\")\n",
    "    \n",
    "    # A. Liaison Orders <-> RFM (via user_id)\n",
    "    print(\"   Liaison Clients et Commandes...\")\n",
    "    df = orders.merge(rfm, on='user_id', how='inner')\n",
    "    \n",
    "    # Nettoyage mémoire : on n'a plus besoin des DataFrames originaux rfm et orders\n",
    "    del rfm\n",
    "    del orders\n",
    "    gc.collect() \n",
    "\n",
    "    # B. Liaison Résultat <-> Order_Products (via order_id)\n",
    "    print(\"   Liaison Commandes et Produits achetés (Opération lourde)...\")\n",
    "    df = df.merge(order_products, on='order_id', how='inner')\n",
    "    \n",
    "    del order_products\n",
    "    # On n'a plus besoin de order_id et user_id pour la suite, on les supprime du tableau !\n",
    "    df.drop(columns=['order_id', 'user_id'], inplace=True) \n",
    "    gc.collect()\n",
    "\n",
    "    # C. Liaison Résultat <-> Products (via product_id)\n",
    "    print(\"   Récupération des noms de produits...\")\n",
    "    df = df.merge(products, on='product_id', how='inner')\n",
    "    \n",
    "    del products\n",
    "    # On n'a plus besoin du product_id, on ne garde que segment et product_name\n",
    "    df.drop(columns=['product_id'], inplace=True)\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa14e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10_products(df):\n",
    "    \"\"\"\n",
    "    Étape 3 : Comptage et extraction du Top 10.\n",
    "    \"\"\"\n",
    "    print(\"3. Comptage des produits par segment...\")\n",
    "    \n",
    "    # On compte combien de fois chaque produit apparait dans chaque segment\n",
    "    counts = df.groupby(['segment', 'product_name']).size().reset_index(name='purchase_count')\n",
    "    \n",
    "    # On trie : par segment (alphabétique) puis par nombre d'achats (décroissant)\n",
    "    print(\"   Tri et extraction du Top 10...\")\n",
    "    counts = counts.sort_values(by=['segment', 'purchase_count'], ascending=[True, False])\n",
    "    \n",
    "    # On groupe par segment et on ne garde que les 10 premières lignes\n",
    "    top_10_df = counts.groupby('segment').head(10)\n",
    "    \n",
    "    return top_10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07bb33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_and_save(top_10_df):\n",
    "    \"\"\"\n",
    "    Étape 4 : Formatage final et Sauvegarde.\n",
    "    Transforme les 10 lignes par segment en 1 seule ligne avec une liste séparée par des virgules.\n",
    "    \"\"\"\n",
    "    print(\"4. Formatage du fichier final...\")\n",
    "    \n",
    "    # Pour chaque segment, on prend la colonne product_name et on joint les valeurs avec \", \"\n",
    "    final_df = top_10_df.groupby('segment')['product_name'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "    \n",
    "    # On renomme la colonne selon ta demande\n",
    "    final_df.rename(columns={'product_name': 'products'}, inplace=True)\n",
    "    \n",
    "    # Sauvegarde\n",
    "    print(f\"   Sauvegarde dans {FILE_OUTPUT}...\")\n",
    "    final_df.to_csv(FILE_OUTPUT, index=False)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(\"SUCCÈS ! Traitement terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43691d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Chargement des fichiers.\n",
      "2. Début des liaisons (Merges)...\n",
      "   Liaison Clients et Commandes...\n",
      "   Liaison Commandes et Produits achetés (Opération lourde)...\n",
      "   Récupération des noms de produits...\n",
      "3. Comptage des produits par segment...\n",
      "   Tri et extraction du Top 10...\n",
      "4. Formatage du fichier final...\n",
      "   Sauvegarde dans final/products_segment.csv...\n",
      "------------------------------\n",
      "SUCCÈS ! Traitement terminé.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Exécution de la pipeline\n",
    "    rfm, orders, order_products, products = load_data()\n",
    "    df_merged = merge_datasets(rfm, orders, order_products, products)\n",
    "    df_top_10 = get_top_10_products(df_merged)\n",
    "    format_and_save(df_top_10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvProject2 (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
