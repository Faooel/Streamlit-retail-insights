{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b645bff5",
   "metadata": {},
   "source": [
    "# Price Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f673e55b",
   "metadata": {},
   "source": [
    "## 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a0cd0",
   "metadata": {},
   "source": [
    "We have two databases. The first is our internal product database, which does not contain any pricing information. The second is an external database containing numerous products with associated prices. Our objective is to integrate these prices into our product database. To do this, we must compare products from both databases and perform a \"match\" based on product names.\n",
    "\n",
    "To achieve this, I used the RapidFuzz library to compare product names using a similarity score. However, a problem arose: the two databases were not in the same language. One contained products in English, while the other (the external database) contained products in various languages, but primarily in French.\n",
    "\n",
    "This creates a significant issue. For example, the word \"Fraise\" in French translates to \"Strawberry\" in English. These words have no lexical resemblance for a standard matching algorithm. I initially attempted to translate one of the files into English using the Google Translate library, but this proved unfeasible due to the volume of data (over 100,000 entries), with an estimated processing time of 24 hours.\n",
    "\n",
    "Consequently, Kali provided a better-organized external price file to reduce processing time. Meanwhile, Antoine provided a file containing the top 1,000 best-selling products from our database (representing 90% of sales). This strategy significantly reduced the volume of values requiring translation.\n",
    "\n",
    "Input files:\n",
    "\n",
    "- top_1000_products.csv: Top 1,000 best-selling products from our database.\n",
    "\n",
    "- prices_final_imputed_translated.csv: External database containing prices.\n",
    "\n",
    "Output file:\n",
    "\n",
    "- final/product_with_price.csv: Top 1,000 best-selling products from our database with integrated prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fe178",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35e41e",
   "metadata": {},
   "source": [
    "### 2.1 Conversion of CSV files to Excel for visual inspection.\n",
    "\n",
    "Input: \"top_1000_products.csv\" and \"Translate_PriceDB/Translate_PriceDB/prices_final_imputed_translated.csv\"  \n",
    "Output: \"a_traiter/product_base.xlsx\" and \"a_traiter/product_prices_non_traite.xlsx\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7edbbe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage de la conversion CSV -> Excel ---\n",
      "\n",
      "1. Traitement de top_1000_products.csv...\n",
      "   -> 1000 lignes lues.\n",
      "   -> Écriture vers a_traiter\\product_base.xlsx...\n",
      "   -> Succès.\n",
      "\n",
      "2. Traitement de prices_final_imputed_translated.csv...\n",
      "   -> 181734 lignes lues.\n",
      "   -> Écriture vers a_traiter\\product_prices_non_traite.xlsx...\n",
      "   -> Succès.\n",
      "\n",
      "--- Opération terminée ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION DES CHEMINS ---\n",
    "# Chemins d'entrée (tels que tu me les as donnés)\n",
    "FILE_1_CSV = \"top_1000_products.csv\"\n",
    "FILE_2_CSV = \"prices_final_imputed_translated.csv\"\n",
    "\n",
    "# Dossier et fichiers de sortie\n",
    "OUT_DIR = \"a_traiter\"\n",
    "FILE_1_XLSX = os.path.join(OUT_DIR, \"product_base.xlsx\")\n",
    "FILE_2_XLSX = os.path.join(OUT_DIR, \"product_prices_non_traite.xlsx\")\n",
    "\n",
    "def convert_to_excel():\n",
    "    print(\"--- Démarrage de la conversion CSV -> Excel ---\")\n",
    "\n",
    "    # 1. Création du dossier de sortie s'il n'existe pas\n",
    "    if not os.path.exists(OUT_DIR):\n",
    "        print(f\"Création du dossier '{OUT_DIR}'...\")\n",
    "        os.makedirs(OUT_DIR)\n",
    "\n",
    "    # --- TRAITEMENT FICHIER 1 : PRODUITS ---\n",
    "    print(f\"\\n1. Traitement de {FILE_1_CSV}...\")\n",
    "    if os.path.exists(FILE_1_CSV):\n",
    "        try:\n",
    "            # Séparateur virgule \",\" pour ce fichier\n",
    "            df_prod = pd.read_csv(FILE_1_CSV, sep=',')\n",
    "            \n",
    "            print(f\"   -> {len(df_prod)} lignes lues.\")\n",
    "            print(f\"   -> Écriture vers {FILE_1_XLSX}...\")\n",
    "            \n",
    "            df_prod.to_excel(FILE_1_XLSX, index=False, engine='openpyxl')\n",
    "            print(\"   -> Succès.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   -> ERREUR : {e}\")\n",
    "    else:\n",
    "        print(f\"   -> ERREUR : Le fichier {FILE_1_CSV} est introuvable.\")\n",
    "\n",
    "    # --- TRAITEMENT FICHIER 2 : PRIX ---\n",
    "    print(f\"\\n2. Traitement de {FILE_2_CSV}...\")\n",
    "    if os.path.exists(FILE_2_CSV):\n",
    "        try:\n",
    "            # Séparateur point-virgule \";\" d'après ton extrait\n",
    "            # On utilise engine='python' pour plus de tolérance sur les erreurs de parsing\n",
    "            df_price = pd.read_csv(FILE_2_CSV, sep=';', engine='python')\n",
    "            \n",
    "            print(f\"   -> {len(df_price)} lignes lues.\")\n",
    "            \n",
    "            # Nettoyage léger pré-Excel :\n",
    "            # Ton extrait montre une première colonne vide (le CSV commence par ;)\n",
    "            # Si une colonne est entièrement vide et sans nom (Unnamed), on peut l'enlever pour la lisibilité\n",
    "            df_price = df_price.dropna(how='all', axis=1) \n",
    "            \n",
    "            print(f\"   -> Écriture vers {FILE_2_XLSX}...\")\n",
    "            # Utilisation de xlsxwriter pour gérer les caractères spéciaux potentiels\n",
    "            df_price.to_excel(FILE_2_XLSX, index=False, engine='xlsxwriter')\n",
    "            print(\"   -> Succès.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   -> ERREUR : {e}\")\n",
    "    else:\n",
    "        print(f\"   -> ERREUR : Le fichier {FILE_2_CSV} est introuvable.\")\n",
    "        print(\"      Vérifie que le chemin (Translate_PriceDB/...) est correct.\")\n",
    "\n",
    "    print(\"\\n--- Opération terminée ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_to_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3b56f",
   "metadata": {},
   "source": [
    "### 2.2 Removal of Unnecessary Columns for Price Integration\n",
    "\n",
    "Columns to retain from the product_prices_non_traite file (the final file will contain only the following columns):  \n",
    "\n",
    "- product_name: Join key. Shared attribute with the product_base file that will enable linking a price to a product.  \n",
    "\n",
    "- price: The displayed retail price value.  \n",
    "\n",
    "- price_without_discount: The \"True Price\" (excluding promotions) to avoid skewing revenue simulations.  \n",
    "\n",
    "- currency: The currency (e.g., $1.00 ≠ €1.00).  \n",
    "\n",
    "- category_tag: Product category.  \n",
    "\n",
    "Input: a_traiter/product_prices_non_traite  \n",
    "Output: a_traiter/product_prices_traite  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2826faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage du filtrage et nettoyage des prix ---\n",
      "Lecture de a_traiter/product_prices_non_traite.xlsx...\n",
      "Conservation uniquement des 5 colonnes cibles...\n",
      "Calcul du 'final_price' (Priorité au prix hors remise)...\n",
      "Nettoyage : 73810 lignes vides supprimées.\n",
      "Sauvegarde vers a_traiter/product_prices_traite.xlsx...\n",
      "--- Succès ! Fichier généré. ---\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE = 'a_traiter/product_prices_non_traite.xlsx'\n",
    "OUTPUT_FILE = 'a_traiter/product_prices_traite.xlsx'\n",
    "\n",
    "# Liste stricte des colonnes demandées\n",
    "COLS_TO_KEEP = [\n",
    "    'product_name', \n",
    "    'price', \n",
    "    'price_without_discount', \n",
    "    'currency', \n",
    "    'category_tag'\n",
    "]\n",
    "\n",
    "def filter_and_clean():\n",
    "    print(\"--- Démarrage du filtrage et nettoyage des prix ---\")\n",
    "\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"ERREUR : Le fichier {INPUT_FILE} est introuvable.\")\n",
    "        return\n",
    "\n",
    "    # 1. Chargement du fichier\n",
    "    print(f\"Lecture de {INPUT_FILE}...\")\n",
    "    try:\n",
    "        df = pd.read_excel(INPUT_FILE, engine='openpyxl')\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de lecture : {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Vérification de la présence des colonnes\n",
    "    missing_cols = [col for col in COLS_TO_KEEP if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"ATTENTION : Colonnes manquantes dans le fichier source : {missing_cols}\")\n",
    "        return\n",
    "\n",
    "    # 3. Sélection des colonnes\n",
    "    print(\"Conservation uniquement des 5 colonnes cibles...\")\n",
    "    df_clean = df[COLS_TO_KEEP].copy()\n",
    "\n",
    "    # 4. Logique Business (Consolidation du Prix)\n",
    "    # On crée 'final_price' ici pour que le fichier 'traité' soit prêt à l'emploi.\n",
    "    # Règle : Si 'price_without_discount' existe, on le prend. Sinon on prend 'price'.\n",
    "    print(\"Calcul du 'final_price' (Priorité au prix hors remise)...\")\n",
    "    df_clean['final_price'] = df_clean['price_without_discount'].fillna(df_clean['price'])\n",
    "\n",
    "    # 5. Nettoyage des lignes invalides\n",
    "    # On supprime si le Nom est vide OU si le Prix Final est vide\n",
    "    initial_len = len(df_clean)\n",
    "    df_clean = df_clean.dropna(subset=['product_name', 'final_price'])\n",
    "    cleaned_len = len(df_clean)\n",
    "    \n",
    "    print(f\"Nettoyage : {initial_len - cleaned_len} lignes vides supprimées.\")\n",
    "\n",
    "    # 6. Sauvegarde\n",
    "    print(f\"Sauvegarde vers {OUTPUT_FILE}...\")\n",
    "    # On garde les colonnes sources + le prix final calculé\n",
    "    cols_export = COLS_TO_KEEP + ['final_price']\n",
    "    \n",
    "    # Réorganisation pour avoir final_price juste après product_name pour la lisibilité\n",
    "    cols_ordered = ['product_name', 'final_price', 'currency', 'category_tag', 'price', 'price_without_discount']\n",
    "    \n",
    "    # On s'assure de ne prendre que ce qui existe (au cas où category_tag serait vide/absent)\n",
    "    final_cols = [c for c in cols_ordered if c in df_clean.columns]\n",
    "    \n",
    "    df_clean[final_cols].to_excel(OUTPUT_FILE, index=False)\n",
    "    print(\"--- Succès ! Fichier généré. ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filter_and_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a8551",
   "metadata": {},
   "source": [
    "### 2.3 Processing the 'category_tag' Column\n",
    "\n",
    "We will now perform processing on the file 'a_traiter/product_prices_traite.xlsx'.\n",
    "\n",
    "'category_tag' column: For each row where the value is not null, the data follows the format \"en:value\" or \"fr:value\". We must retain only the value (everything to the right of the \":\"). The language prefix is unnecessary; the product data must be \"clean\".\n",
    "\n",
    "The Excel file is then saved using the same filename (overwriting the original)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Nettoyage de la colonne 'category_tag' dans a_traiter/product_prices_traite.xlsx ---\n",
      "Chargement du fichier...\n",
      "Nettoyage des préfixes (en:, fr:, etc.)...\n",
      "Sauvegarde (écrasement du fichier original)...\n",
      "SUCCÈS : Le fichier a été mis à jour.\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "FILE_PATH = 'a_traiter/product_prices_traite.xlsx'\n",
    "\n",
    "def clean_tags():\n",
    "    print(f\"--- Nettoyage de la colonne 'category_tag' dans {FILE_PATH} ---\")\n",
    "\n",
    "    # 1. Vérification de l'existence du fichier\n",
    "    if not os.path.exists(FILE_PATH):\n",
    "        print(f\"ERREUR : Le fichier {FILE_PATH} est introuvable.\")\n",
    "        return\n",
    "\n",
    "    # 2. Chargement du fichier Excel\n",
    "    print(\"Chargement du fichier...\")\n",
    "    try:\n",
    "        df = pd.read_excel(FILE_PATH, engine='openpyxl')\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture : {e}\")\n",
    "        return\n",
    "\n",
    "    # 3. Fonction de nettoyage\n",
    "    def remove_prefix(text):\n",
    "        \"\"\"\n",
    "        Si le texte est 'en:bananas', retourne 'bananas'.\n",
    "        Si le texte est vide ou sans ':', retourne le texte original.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str) and ':' in text:\n",
    "            # On coupe au PREMIER ':' rencontré et on prend la suite\n",
    "            # split(':', 1) permet de gérer les cas où la valeur contiendrait aussi un ':'\n",
    "            return text.split(':', 1)[1]\n",
    "        return text\n",
    "\n",
    "    # 4. Application du nettoyage\n",
    "    if 'category_tag' in df.columns:\n",
    "        print(\"Nettoyage des préfixes (en:, fr:, etc.)...\")\n",
    "        # On applique la fonction sur toute la colonne\n",
    "        df['category_tag'] = df['category_tag'].apply(remove_prefix)\n",
    "    else:\n",
    "        print(\"ATTENTION : La colonne 'category_tag' n'existe pas dans ce fichier.\")\n",
    "\n",
    "    # 5. Sauvegarde (Écrasement du fichier)\n",
    "    print(\"Sauvegarde (écrasement du fichier original)...\")\n",
    "    try:\n",
    "        df.to_excel(FILE_PATH, index=False, engine='openpyxl')\n",
    "        print(\"SUCCÈS : Le fichier a été mis à jour.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde : {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7caee8",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "\n",
    "We will translate the product_name column from the file \"matching/product_base.xlsx\" into a new file: \"matching/base_product_fr.xlsx\".  \n",
    "\n",
    "Translation is performed from English to French into a new column, product_fr (the original English product_name column must be retained).  \n",
    "\n",
    "Consequently, our database file will ultimately contain two product name columns: one in English and one in French. For a more robust comparison, we will subsequently evaluate both columns during the matching process and select the highest score between the English and French versions.  \n",
    "\n",
    "We use the tqdm library to monitor progress and the GoogleTranslator library for the translation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage de la traduction (EN -> FR) ---\n",
      "Lecture de a_traiter/product_base.xlsx...\n",
      "   -> 1000 produits à traduire.\n",
      "Traduction en cours (veuillez patienter)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progression: 100%|██████████| 1000/1000 [18:12<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde vers a_traiter/product_base_fr.xlsx...\n",
      "--- Terminé avec succès ! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from deep_translator import GoogleTranslator\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE = 'a_traiter/product_base.xlsx'\n",
    "OUTPUT_FILE = 'a_traiter/product_base_fr.xlsx'\n",
    "\n",
    "def translate_base():\n",
    "    print(\"--- Démarrage de la traduction (EN -> FR) ---\")\n",
    "\n",
    "    # 1. Vérification du fichier\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"ERREUR : Le fichier {INPUT_FILE} est introuvable.\")\n",
    "        return\n",
    "\n",
    "    # 2. Chargement\n",
    "    print(f\"Lecture de {INPUT_FILE}...\")\n",
    "    try:\n",
    "        df = pd.read_excel(INPUT_FILE, engine='openpyxl')\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de lecture : {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"   -> {len(df)} produits à traduire.\")\n",
    "\n",
    "    # 3. Initialisation du traducteur\n",
    "    # source='en' (Anglais) -> target='fr' (Français)\n",
    "    translator = GoogleTranslator(source='en', target='fr')\n",
    "\n",
    "    # 4. Fonction de traduction sécurisée\n",
    "    def safe_translate(text):\n",
    "        if not isinstance(text, str) or len(text) < 2:\n",
    "            return text\n",
    "        try:\n",
    "            return translator.translate(text)\n",
    "        except Exception:\n",
    "            return text  # En cas d'erreur (timeout), on retourne le texte original\n",
    "\n",
    "    # 5. Application avec barre de progression (tqdm)\n",
    "    print(\"Traduction en cours (veuillez patienter)...\")\n",
    "    \n",
    "    # On active tqdm pour pandas\n",
    "    tqdm.pandas(desc=\"Progression\")\n",
    "    \n",
    "    # Création de la nouvelle colonne 'product_name_fr'\n",
    "    # On garde 'product_name' intact\n",
    "    df['product_name_fr'] = df['product_name'].progress_apply(safe_translate)\n",
    "\n",
    "    # 6. Sauvegarde\n",
    "    print(f\"Sauvegarde vers {OUTPUT_FILE}...\")\n",
    "    \n",
    "    # On réorganise les colonnes pour avoir la traduction juste après le nom original\n",
    "    cols = list(df.columns)\n",
    "    if 'product_name' in cols and 'product_name_fr' in cols:\n",
    "        # On place product_name_fr juste après product_name\n",
    "        index_original = cols.index('product_name')\n",
    "        cols.remove('product_name_fr')\n",
    "        cols.insert(index_original + 1, 'product_name_fr')\n",
    "        df = df[cols]\n",
    "\n",
    "    df.to_excel(OUTPUT_FILE, index=False, engine='openpyxl')\n",
    "    print(\"--- Terminé avec succès ! ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    translate_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d50f8",
   "metadata": {},
   "source": [
    "## 4. Normalization\n",
    "\n",
    "We will normalize the product_name column values in both files to facilitate the comparison process.\n",
    "\n",
    "We will remove uppercase letters, accents, and leading/trailing whitespace. This preprocessing step is designed to optimize the matching algorithm.\n",
    "\n",
    "Once completed, the two files are saved into the new \"matching/\" directory.\n",
    "\n",
    "Note: The final output must contain the original, correct product name (un-normalized). The standardization performed on these two files is strictly for matching purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97587cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Préparation des fichiers pour le Matching ---\n",
      "Traitement de product_prices_traite.xlsx...\n",
      "   -> Mode : Normalisation Simple\n",
      "   -> Sauvegarde dans matching/...\n",
      "Traitement de product_base_fr.xlsx...\n",
      "   -> Mode : Double Normalisation (Original & FR)\n",
      "   -> Sauvegarde dans matching/...\n",
      "------------------------------\n",
      "Succès ! Les fichiers sont prêts dans le dossier 'matching/'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_DIR = 'a_traiter'\n",
    "OUTPUT_DIR = 'matching'\n",
    "\n",
    "FILES_TO_PROCESS = [\n",
    "    'product_prices_traite.xlsx',\n",
    "    'product_base_fr.xlsx'\n",
    "]\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Fonction de nettoyage strict pour le matching :\n",
    "    - Minuscules\n",
    "    - Suppression des accents (café -> cafe)\n",
    "    - Remplacement de la ponctuation par des espaces\n",
    "    - Suppression des espaces multiples et trim\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. Minuscules\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Retrait des accents (nécessite unidecode)\n",
    "    text = unidecode(text)\n",
    "    \n",
    "    # 3. On ne garde que les lettres (a-z) et les chiffres (0-9)\n",
    "    text = re.sub(r'[^a-z0-9]', ' ', text)\n",
    "    \n",
    "    # 4. On nettoie les espaces multiples\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def prepare_files():\n",
    "    print(\"--- Préparation des fichiers pour le Matching ---\")\n",
    "    \n",
    "    # Création du dossier de sortie\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    for filename in FILES_TO_PROCESS:\n",
    "        input_path = os.path.join(INPUT_DIR, filename)\n",
    "        output_path = os.path.join(OUTPUT_DIR, filename)\n",
    "        \n",
    "        if not os.path.exists(input_path):\n",
    "            print(f\"ERREUR : Fichier introuvable -> {input_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Traitement de {filename}...\")\n",
    "        \n",
    "        try:\n",
    "            # Lecture\n",
    "            df = pd.read_excel(input_path, engine='openpyxl')\n",
    "            \n",
    "            # --- LOGIQUE SPÉCIFIQUE SELON LE FICHIER ---\n",
    "            \n",
    "            if 'product_base_fr.xlsx' in filename:\n",
    "                print(\"   -> Mode : Double Normalisation (Original & FR)\")\n",
    "                \n",
    "                # 1. Normalisation de la colonne originale (product_name -> product_name_normalized)\n",
    "                if 'product_name' in df.columns:\n",
    "                    df['product_name_normalized'] = df['product_name'].apply(normalize_text)\n",
    "                else:\n",
    "                    print(\"      ATTENTION: 'product_name' introuvable.\")\n",
    "\n",
    "                # 2. Normalisation de la colonne traduite (product_name_fr -> product_name_fr_normalized)\n",
    "                if 'product_name_fr' in df.columns:\n",
    "                    df['product_name_fr_normalized'] = df['product_name_fr'].apply(normalize_text)\n",
    "                else:\n",
    "                    print(\"      ATTENTION: 'product_name_fr' introuvable.\")\n",
    "                    \n",
    "            else:\n",
    "                # Cas du fichier de PRIX (product_prices_traite.xlsx)\n",
    "                print(\"   -> Mode : Normalisation Simple\")\n",
    "                if 'product_name' in df.columns:\n",
    "                    df['product_name_normalized'] = df['product_name'].apply(normalize_text)\n",
    "                else:\n",
    "                    print(\"      ERREUR : La colonne 'product_name' est absente.\")\n",
    "                    continue\n",
    "\n",
    "            # Sauvegarde\n",
    "            print(f\"   -> Sauvegarde dans {OUTPUT_DIR}/...\")\n",
    "            df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   -> ERREUR CRITIQUE : {e}\")\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Succès ! Les fichiers sont prêts dans le dossier 'matching/'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea1f5a",
   "metadata": {},
   "source": [
    "## 5. Matching\n",
    "\n",
    "We perform the matching process by comparing data from the \"matching/product_base_fr.xlsx\" file against the \"matching/product_price_traite.xlsx\" file.\n",
    "\n",
    "For each row in product_base_fr, we compare the following two columns: product_name_normalized and product_name_fr_normalized against the product_name_normalized column of the product_price_traite file. We then retrieve the highest match score relative to the values in the price file.\n",
    "\n",
    "Here, we compare the product in both English and French to retain the higher of the two scores, given that the language of the products in the product_price_traite file is not known in advance. This ensures greater robustness and superior results.\n",
    "\n",
    "Once the highest score is identified, we retrieve the currency and price values to append them to the product_base_fr file.\n",
    "\n",
    "The final file will contain the following columns:\n",
    "rank, product_id, product_name, product_name_fr, nb_purchases, currency, price, score, source\n",
    "\n",
    "The source column will contain one of two values: \"fr\" or \"en\". If the highest score was derived from the product_name_normalized value, we assign \"en\"; otherwise, if the highest score was derived from the product_name_fr_normalized value, we assign \"fr\".\n",
    "\n",
    "Output: \"final/product_with_price.xlsx\"\n",
    "\n",
    "We also export it to CSV: \"final/product_with_price.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a116a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage du Matching Final (Duel FR vs EN) ---\n",
      "Chargement des données...\n",
      "   -> Base produits (Instacart) : 1000 lignes\n",
      "   -> Base prix (OpenFoodFacts) : 107924 lignes\n",
      "Calcul des scores en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:53<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construction du fichier final...\n",
      "Sauvegarde Excel : final\\product_with_price.xlsx\n",
      "Sauvegarde CSV : final\\product_with_price.csv\n",
      "------------------------------\n",
      "TERMINÉ ! Tu peux analyser les scores dans le dossier 'final/'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from rapidfuzz import process, fuzz\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_BASE = 'matching/product_base_fr.xlsx'\n",
    "# Attention : je corrige le nom ici ('prices' au pluriel comme généré précédemment)\n",
    "INPUT_PRICES = 'matching/product_prices_traite.xlsx' \n",
    "\n",
    "OUTPUT_DIR = 'final'\n",
    "OUTPUT_XLSX = os.path.join(OUTPUT_DIR, 'product_with_price.xlsx')\n",
    "OUTPUT_CSV = os.path.join(OUTPUT_DIR, 'product_with_price.csv')\n",
    "\n",
    "def run_matching():\n",
    "    print(\"--- Démarrage du Matching Final (Duel FR vs EN) ---\")\n",
    "\n",
    "    # 1. Chargement des fichiers\n",
    "    print(\"Chargement des données...\")\n",
    "    if not os.path.exists(INPUT_BASE) or not os.path.exists(INPUT_PRICES):\n",
    "        print(\"ERREUR : Fichiers d'entrée introuvables dans le dossier 'matching/'.\")\n",
    "        return\n",
    "\n",
    "    df_base = pd.read_excel(INPUT_BASE, engine='openpyxl')\n",
    "    df_prices = pd.read_excel(INPUT_PRICES, engine='openpyxl')\n",
    "\n",
    "    print(f\"   -> Base produits (Instacart) : {len(df_base)} lignes\")\n",
    "    print(f\"   -> Base prix (OpenFoodFacts) : {len(df_prices)} lignes\")\n",
    "\n",
    "    # 2. Préparation pour RapidFuzz\n",
    "    # On crée une liste des noms normalisés du fichier PRIX pour la recherche\n",
    "    # On s'assure que ce sont des chaines de caractères (str)\n",
    "    price_choices = df_prices['product_name_normalized'].astype(str).tolist()\n",
    "\n",
    "    # On prépare les listes pour stocker les résultats\n",
    "    results_currency = []\n",
    "    results_price = []\n",
    "    results_score = []\n",
    "    results_source = []\n",
    "\n",
    "    print(\"Calcul des scores en cours...\")\n",
    "    \n",
    "    # On itère sur chaque produit de la base\n",
    "    # tqdm affiche une barre de progression\n",
    "    for i, row in tqdm(df_base.iterrows(), total=df_base.shape[0]):\n",
    "        \n",
    "        # --- MATCHING ANGLAIS ---\n",
    "        name_en = str(row['product_name_normalized'])\n",
    "        # process.extractOne retourne : (match_string, score, index)\n",
    "        match_en = process.extractOne(name_en, price_choices, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        # --- MATCHING FRANCAIS ---\n",
    "        name_fr = str(row['product_name_fr_normalized'])\n",
    "        match_fr = process.extractOne(name_fr, price_choices, scorer=fuzz.token_sort_ratio)\n",
    "\n",
    "        # --- LE DUEL : QUI A LE MEILLEUR SCORE ? ---\n",
    "        # match_en[1] est le score, match_en[2] est l'index dans df_prices\n",
    "        \n",
    "        score_en = match_en[1]\n",
    "        score_fr = match_fr[1]\n",
    "\n",
    "        if score_en >= score_fr:\n",
    "            # L'anglais gagne (ou égalité)\n",
    "            best_score = score_en\n",
    "            best_index = match_en[2]\n",
    "            source = \"en\"\n",
    "        else:\n",
    "            # Le français gagne\n",
    "            best_score = score_fr\n",
    "            best_index = match_fr[2]\n",
    "            source = \"fr\"\n",
    "\n",
    "        # Récupération des données du gagnant dans le fichier PRIX\n",
    "        price_row = df_prices.iloc[best_index]\n",
    "        \n",
    "        results_score.append(best_score)\n",
    "        results_source.append(source)\n",
    "        results_price.append(price_row['final_price'])\n",
    "        results_currency.append(price_row['currency'])\n",
    "\n",
    "    # 3. Construction du DataFrame final\n",
    "    print(\"Construction du fichier final...\")\n",
    "    df_base['currency'] = results_currency\n",
    "    df_base['price'] = results_price\n",
    "    df_base['score'] = results_score\n",
    "    df_base['source'] = results_source\n",
    "\n",
    "    # Sélection des colonnes demandées\n",
    "    final_cols = [\n",
    "        'rank', \n",
    "        'product_id', \n",
    "        'product_name', \n",
    "        'product_name_fr', \n",
    "        'nb_purchases', \n",
    "        'currency', \n",
    "        'price', \n",
    "        'score', \n",
    "        'source'\n",
    "    ]\n",
    "    \n",
    "    # On filtre pour ne garder que ces colonnes (si elles existent)\n",
    "    cols_to_export = [c for c in final_cols if c in df_base.columns]\n",
    "    df_final = df_base[cols_to_export]\n",
    "\n",
    "    # 4. Sauvegarde\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"Sauvegarde Excel : {OUTPUT_XLSX}\")\n",
    "    df_final.to_excel(OUTPUT_XLSX, index=False, engine='openpyxl')\n",
    "    \n",
    "    print(f\"Sauvegarde CSV : {OUTPUT_CSV}\")\n",
    "    df_final.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"TERMINÉ ! Tu peux analyser les scores dans le dossier 'final/'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_matching()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6623422",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b941d4",
   "metadata": {},
   "source": [
    "I selected the RapidFuzz library for its efficiency in string similarity comparison. Additionally, resource constraints prevented the use of an AI model capable of native cross-lingual product matching (such as ChatGPT). Furthermore, this technology delivers robust results through its scoring mechanism.  \n",
    "\n",
    "Scoring Mechanism:  \n",
    "We utilize the RapidFuzz algorithm with the token_sort_ratio method. This approach disregards word order (e.g., 'Organic Milk' = 'Milk Organic') and tolerates minor spelling variations.  \n",
    "\n",
    "For each product, we perform two parallel searches within the price database: one using the English name and one using the French translation. We systematically retain the result with the highest confidence score (the Max), allowing us to retrieve the most relevant price regardless of the product's source language.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvProject2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
