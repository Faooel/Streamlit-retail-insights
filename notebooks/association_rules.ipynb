{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beeac71f",
   "metadata": {},
   "source": [
    "### ASSOCIATION RULES - ALL APPROACHES\n",
    "\n",
    "This notebook generates and evaluates association rules using 3 approaches:\n",
    "1. By Department (intra-department rules)\n",
    "2. Cross-Department (global rules across all departments)\n",
    "3. By Segment (RFM segment-specific rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af4550",
   "metadata": {},
   "source": [
    "## I. Import and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84630790",
   "metadata": {},
   "source": [
    "### I.1. Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fa24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../scripts')  # To import from parent directory\n",
    "\n",
    "from load_data import load_instacart_data\n",
    "from split_data import temporal_split_instacart\n",
    "from functions_association_rules import (\n",
    "    prepare_transactions,\n",
    "    generate_association_rules,\n",
    "    evaluate_rules,\n",
    "    print_evaluation_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9635af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_instacart_data()\n",
    "\n",
    "orders = data['orders']\n",
    "order_products_prior = data['order_products_prior']\n",
    "order_products_train = data['order_products_train']\n",
    "products = data['products']\n",
    "departments = data['departments']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb460c12",
   "metadata": {},
   "source": [
    "### I.2. Generate train/testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09a1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating new split...\n",
      "\n",
      "[1/6] Merging prior + train datasets...\n",
      "  Total rows: 33,819,106\n",
      "  Unique orders: 3,346,083\n",
      "  Unique products: 49,685\n",
      "\n",
      "[2/6] Temporal split based on order_number...\n",
      "  Total orders: 3,421,083\n",
      "  Train orders: 2,394,758 (70.0%)\n",
      "  Test orders: 1,026,325 (30.0%)\n",
      "\n",
      "  Train rows: 23,558,148\n",
      "  Test rows: 10,260,958\n",
      "\n",
      "[3/6] Checking basket size distributions...\n",
      "\n",
      "  TRAIN - Basket Size:\n",
      "    Mean: 10.07, Median: 8, Std: 7.53\n",
      "    Range: [1, 145]\n",
      "\n",
      "  TEST - Basket Size:\n",
      "    Mean: 10.19, Median: 8, Std: 7.57\n",
      "    Range: [1, 137]\n",
      "\n",
      "  ðŸ“Š Distribution Comparison:\n",
      "    Train vs Test: Î” mean = 0.11 âœ…\n",
      "\n",
      "[4/6] Checking department diversity distributions...\n",
      "\n",
      "  TRAIN - Department Diversity:\n",
      "    Mean: 4.76, Median: 4, Std: 2.57\n",
      "\n",
      "  TEST - Department Diversity:\n",
      "    Mean: 4.70, Median: 4, Std: 2.50\n",
      "\n",
      "  ðŸ“Š Distribution Comparison:\n",
      "    Train vs Test: Î” mean = 0.06 âœ…\n",
      "\n",
      "[6/6] Saving splits...\n",
      "  âœ… Train saved: ../data/processed/train.csv (23,558,148 rows)\n",
      "  âœ… Test saved: ../data/processed/test.csv (10,260,958 rows)\n"
     ]
    }
   ],
   "source": [
    "# Check if split already exists\n",
    "if os.path.exists('../data/processed/train.csv') and os.path.exists('../data/processed/test.csv'):\n",
    "    print(\"  Split files already exist, loading from disk...\")\n",
    "    train = pd.read_csv('../data/processed/train.csv')\n",
    "    test = pd.read_csv('../data/processed/test.csv')\n",
    "else:\n",
    "    print(\"  Creating new split...\")\n",
    "    splits = temporal_split_instacart(\n",
    "        order_products_prior=order_products_prior,\n",
    "        order_products_train=order_products_train,\n",
    "        orders=orders,\n",
    "        products=products,\n",
    "        departments=departments,\n",
    "        train_ratio=0.7,  # 70% train, 30% test\n",
    "        save_path='../data/processed/'\n",
    "    )\n",
    "    \n",
    "    train = splits['train']\n",
    "    test = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4200079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Enriching train/test with product and department info...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  Enriching train/test with product and department info...\u001b[39m\u001b[33m\"\u001b[39m)    \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Merge train/test with product and department info\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_enriched = \u001b[43mtrain\u001b[49m.merge(products[[\u001b[33m'\u001b[39m\u001b[33mproduct_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mproduct_name\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdepartment_id\u001b[39m\u001b[33m'\u001b[39m]], \n\u001b[32m      6\u001b[39m     on=\u001b[33m'\u001b[39m\u001b[33mproduct_id\u001b[39m\u001b[33m'\u001b[39m).merge(departments[[\u001b[33m'\u001b[39m\u001b[33mdepartment_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdepartment\u001b[39m\u001b[33m'\u001b[39m]], on=\u001b[33m'\u001b[39m\u001b[33mdepartment_id\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m train\n\u001b[32m      9\u001b[39m gc.collect()\n",
      "\u001b[31mNameError\u001b[39m: name 'train' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gc \n",
    "\n",
    "print(\"  Enriching train/test with product and department info...\")    \n",
    "# Merge train/test with product and department info\n",
    "train_enriched = train.merge(products[['product_id', 'product_name', 'department_id']], \n",
    "    on='product_id').merge(departments[['department_id', 'department']], on='department_id')\n",
    "\n",
    "del train\n",
    "gc.collect()\n",
    "\n",
    "test_enriched = test.merge(products[['product_id', 'product_name', 'department_id']], \n",
    "        on='product_id').merge(departments[['department_id', 'department']], on='department_id')\n",
    "\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceaeb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enriched.to_csv('../data/processed/train_enriched.csv', index=False)\n",
    "test_enriched.to_csv('../data/processed/test_enriched.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f2f78",
   "metadata": {},
   "source": [
    "## II. Association rules on top N products (no filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f2520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total transactions: 1,831,459\n",
      "\n",
      "Total top products rules: 82\n",
      "\n",
      "Evaluating top products rules...\n",
      "  Precision@10: 8.70%\n",
      "  Recall@10: 3.19%\n",
      "  Coverage: 48.87%\n",
      "  Average hits: 0.22\n",
      "  Baskets evaluated: 10,000\n",
      "  Baskets with recommendations: 4,887\n"
     ]
    }
   ],
   "source": [
    "# Without department filter, just on top global products\n",
    "# Prepare transactions (no department filter, top global products)\n",
    "transactions_general = prepare_transactions(\n",
    "    train_enriched,\n",
    "    top_n_products=200  # Top 200 products across ALL departments\n",
    ")\n",
    "\n",
    "print(f\"  Total transactions: {len(transactions_general):,}\")\n",
    "\n",
    "# Generate rules\n",
    "general_rules = generate_association_rules(\n",
    "    transactions_general,\n",
    "    min_support=0.005,\n",
    "    min_confidence=0.15,\n",
    "    min_lift=1.3,\n",
    "    max_transactions=200_000\n",
    ")\n",
    "\n",
    "if general_rules is not None:\n",
    "    print(\"\\n General top products rules...\")\n",
    "    general_rules.to_csv('../data/processed/rules_top_products.csv', index=False)\n",
    "    print(f\"\\nTotal top products rules: {len(general_rules):,}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nEvaluating top products rules...\")\n",
    "    metrics_general = evaluate_rules(\n",
    "        rules=general_rules,\n",
    "        test_data=test_enriched,\n",
    "        k=10\n",
    "    )\n",
    "    print_evaluation_results(metrics_general)\n",
    "else:\n",
    "    print(\"No top products rules generated\")\n",
    "    metrics_general = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4df7b8",
   "metadata": {},
   "source": [
    "Not very interesting => only associations between products from 'Produce' department"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821a5b7",
   "metadata": {},
   "source": [
    "## III. Association rules inside each departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fbb0a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1/18] produce... 180 rules\n",
      "  [2/18] dairy eggs... 20 rules\n",
      "  [3/18] snacks... 4 rules\n",
      "  [4/18] beverages... 20 rules\n",
      "  [5/18] frozen... 6 rules\n",
      "  [6/18] pantry... No rules\n",
      "  [7/18] household... 3 rules\n",
      "  [8/18] personal care... 4 rules\n",
      "  [9/18] bakery... No rules\n",
      "  [10/18] dry goods pasta... 2 rules\n",
      "  [11/18] deli... No rules\n",
      "  [12/18] meat seafood... No rules\n",
      "  [13/18] canned goods... No rules\n",
      "  [14/18] international... No rules\n",
      "  [15/18] breakfast... No rules\n",
      "  [16/18] alcohol... 6 rules\n",
      "  [17/18] babies... 166 rules\n",
      "  [18/18] pets... 66 rules\n",
      "\n",
      "Total rules by department: 477\n",
      "\n",
      "Evaluating rules by department...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEvaluating rules by department...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m metrics_dept = \u001b[43mevaluate_rules\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdept_rules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_enriched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroupby_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdepartment\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     56\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m print_evaluation_results(metrics_dept)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/notebooks/../scripts/functions_association_rules.py:223\u001b[39m, in \u001b[36mevaluate_rules\u001b[39m\u001b[34m(rules, test_data, groupby_column, k, sample_size, min_basket_size)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# Step 1: Group test data by order to create baskets\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m groupby_column:\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# With grouping: keep track of department/segment per basket\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     test_baskets = \u001b[43mtest_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43morder_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mproduct_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroupby_column\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfirst\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# simplify to one value per basket => can be problematic \u001b[39;49;00m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.reset_index()\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# Without grouping: just aggregate products per order\u001b[39;00m\n\u001b[32m    229\u001b[39m     test_baskets = test_data.groupby(\u001b[33m'\u001b[39m\u001b[33morder_id\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mproduct_name\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28mlist\u001b[39m).reset_index()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/groupby/generic.py:2291\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   2288\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   2290\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2291\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2293\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   2294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/apply.py:294\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/apply.py:511\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    504\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    506\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    509\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    510\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/apply.py:1677\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1672\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1674\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1675\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1676\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1677\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1680\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1681\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/apply.py:592\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cols.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    591\u001b[39m     series = obj._gotitem(key, ndim=\u001b[32m1\u001b[39m, subset=cols)\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     results.append(\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    593\u001b[39m     keys.append(key)\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/groupby/generic.py:493\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    484\u001b[39m     obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(\n\u001b[32m    486\u001b[39m         \u001b[38;5;28mself\u001b[39m.obj._constructor(\n\u001b[32m    487\u001b[39m             [],\n\u001b[32m   (...)\u001b[39m\u001b[32m    491\u001b[39m         )\n\u001b[32m    492\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/groupby/generic.py:501\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general\u001b[39m\u001b[34m(self, func, *args, **kwargs)\u001b[39m\n\u001b[32m    498\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, *args, **kwargs)\n\u001b[32m    500\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m res = obj._constructor(result, name=obj.name)\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/groupby/ops.py:989\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    977\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m    978\u001b[39m \u001b[33;03m----------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    986\u001b[39m \u001b[33;03mnp.ndarray or ExtensionArray\u001b[39;00m\n\u001b[32m    987\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    988\u001b[39m result = \u001b[38;5;28mself\u001b[39m._aggregate_series_pure_python(obj, func)\n\u001b[32m--> \u001b[39m\u001b[32m989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cast_pointwise_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:557\u001b[39m, in \u001b[36mCategorical._cast_pointwise_result\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n\u001b[32m    553\u001b[39m     warnings.filterwarnings(\n\u001b[32m    554\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    555\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConstructing a Categorical with a dtype and values containing\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    556\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     cat = \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (cat.isna() == isna(res)).all():\n\u001b[32m    559\u001b[39m     \u001b[38;5;66;03m# i.e. the conversion was non-lossy\u001b[39;00m\n\u001b[32m    560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:548\u001b[39m, in \u001b[36mCategorical._from_sequence\u001b[39m\u001b[34m(cls, scalars, dtype, copy)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_sequence\u001b[39m(\n\u001b[32m    546\u001b[39m     \u001b[38;5;28mcls\u001b[39m, scalars, *, dtype: Dtype | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    547\u001b[39m ) -> Self:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscalars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:504\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, values, categories, ordered, dtype, copy)\u001b[39m\n\u001b[32m    495\u001b[39m     codes = recode_for_categories(\n\u001b[32m    496\u001b[39m         old_codes,\n\u001b[32m    497\u001b[39m         values.dtype.categories,\n\u001b[32m   (...)\u001b[39m\u001b[32m    500\u001b[39m         warn=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    501\u001b[39m     )\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m     codes = \u001b[43m_get_codes_for_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m null_mask.any():\n\u001b[32m    507\u001b[39m     \u001b[38;5;66;03m# Reinsert -1 placeholders for previously removed missing values\u001b[39;00m\n\u001b[32m    508\u001b[39m     full_codes = -np.ones(null_mask.shape, dtype=codes.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/arrays/categorical.py:3042\u001b[39m, in \u001b[36m_get_codes_for_values\u001b[39m\u001b[34m(values, categories)\u001b[39m\n\u001b[32m   3033\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_codes_for_values\u001b[39m(\n\u001b[32m   3034\u001b[39m     values: Index | Series | ExtensionArray | np.ndarray,\n\u001b[32m   3035\u001b[39m     categories: Index,\n\u001b[32m   3036\u001b[39m ) -> np.ndarray:\n\u001b[32m   3037\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3038\u001b[39m \u001b[33;03m    utility routine to turn values into codes given the specified categories\u001b[39;00m\n\u001b[32m   3039\u001b[39m \n\u001b[32m   3040\u001b[39m \u001b[33;03m    If `values` is known to be a Categorical, use recode_for_categories instead.\u001b[39;00m\n\u001b[32m   3041\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3042\u001b[39m     codes = \u001b[43mcategories\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_indexer_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3043\u001b[39m     wrong = (codes == -\u001b[32m1\u001b[39m) & ~isna(values)\n\u001b[32m   3044\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wrong.any():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6284\u001b[39m, in \u001b[36mIndex.get_indexer_for\u001b[39m\u001b[34m(self, target)\u001b[39m\n\u001b[32m   6254\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6255\u001b[39m \u001b[33;03mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[32m   6256\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   6281\u001b[39m \u001b[33;03marray([0, 2])\u001b[39;00m\n\u001b[32m   6282\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_as_unique:\n\u001b[32m-> \u001b[39m\u001b[32m6284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6285\u001b[39m indexer, _ = \u001b[38;5;28mself\u001b[39m.get_indexer_non_unique(target)\n\u001b[32m   6286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3792\u001b[39m, in \u001b[36mIndex.get_indexer\u001b[39m\u001b[34m(self, target, method, limit, tolerance)\u001b[39m\n\u001b[32m   3790\u001b[39m     this = \u001b[38;5;28mself\u001b[39m.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   3791\u001b[39m     target = target.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m3792\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthis\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3793\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\n\u001b[32m   3794\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_indexer(target, method, limit, tolerance)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Retail-Data-Insights/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3823\u001b[39m, in \u001b[36mIndex._get_indexer\u001b[39m\u001b[34m(self, target, method, limit, tolerance)\u001b[39m\n\u001b[32m   3820\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3821\u001b[39m         tgt_values = target._get_engine_target()\n\u001b[32m-> \u001b[39m\u001b[32m3823\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:374\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_indexer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7719\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Rules inside each department\n",
    "\n",
    "# Configuration tiers\n",
    "TIER_1 = ['produce', 'dairy eggs', 'snacks', 'beverages', 'frozen']\n",
    "TIER_2 = ['pantry', 'household', 'personal care', 'bakery', 'dry goods pasta']\n",
    "TIER_3 = ['deli', 'meat seafood', 'canned goods', 'international', 'breakfast', 'alcohol', 'babies', 'pets']\n",
    "\n",
    "dept_config = {\n",
    "    **{d: {'n_products': 100, 'max_trans': 150_000, 'supp': 0.003, 'conf': 0.15, 'lift': 1.3} for d in TIER_1},\n",
    "    **{d: {'n_products': 80, 'max_trans': 100_000, 'supp': 0.003, 'conf': 0.10, 'lift': 1.3} for d in TIER_2},\n",
    "    **{d: {'n_products': 60, 'max_trans': 50_000, 'supp': 0.005, 'conf': 0.12, 'lift': 1.3} for d in TIER_3}\n",
    "}\n",
    "\n",
    "all_dept_rules = []\n",
    "\n",
    "for i, (dept, config) in enumerate(dept_config.items(), 1):\n",
    "    print(f\"  [{i}/{len(dept_config)}] {dept}...\", end=' ')\n",
    "    \n",
    "    # Prepare transactions for this department\n",
    "    transactions = prepare_transactions(\n",
    "        train_enriched,\n",
    "        filter_column='department',\n",
    "        filter_values=dept,\n",
    "        top_n_products=config['n_products']\n",
    "    )\n",
    "    \n",
    "    # Generate rules\n",
    "    rules = generate_association_rules(\n",
    "        transactions,\n",
    "        min_support=config['supp'],\n",
    "        min_confidence=config['conf'],\n",
    "        min_lift=config['lift'],\n",
    "        max_transactions=config['max_trans']\n",
    "    )\n",
    "    \n",
    "    if rules is not None:\n",
    "        rules['department'] = dept\n",
    "        all_dept_rules.append(rules)\n",
    "        print(f\"{len(rules)} rules\")\n",
    "    else:\n",
    "        print(\"No rules\")\n",
    "\n",
    "# Consolidate\n",
    "dept_rules = pd.concat(all_dept_rules, ignore_index=True)\n",
    "dept_rules.to_csv('../data/processed/rules_by_department.csv', index=False)\n",
    "\n",
    "print(f\"\\nTotal rules by department: {len(dept_rules):,}\")\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nEvaluating rules by department...\")\n",
    "metrics_dept = evaluate_rules(\n",
    "    rules=dept_rules,\n",
    "    test_data=test_enriched,\n",
    "    groupby_column='department',\n",
    "    k=10\n",
    ")\n",
    "print_evaluation_results(metrics_dept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20f78b",
   "metadata": {},
   "source": [
    "## IV. Association rules for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f79bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments=pd.read_csv('../data/processed/rfm_customer_segments.csv', usecols=['user_id', 'segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fcd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge train_enriched and test_enriched with segments to get segment info for each transaction\n",
    "# ATTENTION ! : peut-Ãªtre sauvgarder train_enriched et test_enriched plutÃ´t que test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6cffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train/test with segments\n",
    "\n",
    "# Merge orders with segments\n",
    "orders_with_segments = orders.merge(segments, on='user_id', how='left')\n",
    "\n",
    "# Add segments to train set\n",
    "train_with_segments = train.merge(\n",
    "    orders_with_segments[['order_id', 'user_id', 'segment']], \n",
    "    on='order_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "del train, orders # for memory management\n",
    "gc.collect()\n",
    "\n",
    "# Add segments to test set\n",
    "test_with_segments = test.merge(\n",
    "    orders_with_segments[['order_id', 'user_id', 'segment']].drop_duplicates('order_id'),\n",
    "    on='order_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "del test, orders_with_segments # for memory management\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n  Merge completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af144d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_segments.to_csv('../data/processed/train_with_segments.csv', index=False)\n",
    "test_with_segments.to_csv('../data/processed/test_with_segments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROACH 3: RULES BY SEGMENT\n",
    "# Load segment data\n",
    "train_seg = pd.read_csv('../data/processed/train_with_segments.csv')\n",
    "test_seg = pd.read_csv('../data/processed/test_with_segments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add product names to segment data\n",
    "import gc\n",
    "\n",
    "train_seg_enriched = train_seg.merge(\n",
    "    products[['product_id', 'product_name']], \n",
    "    on='product_id'\n",
    ")\n",
    "\n",
    "del train_seg  # Free memory\n",
    "gc.collect()\n",
    "\n",
    "test_seg_enriched = test_seg.merge(\n",
    "    products[['product_id', 'product_name']], \n",
    "    on='product_id'\n",
    ")\n",
    "\n",
    "del test_seg  # Free memory\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get segments\n",
    "segments = train_seg_enriched['segment'].dropna().unique()\n",
    "print(f\"  Segments: {len(segments)}\")\n",
    "\n",
    "all_seg_rules = []\n",
    "\n",
    "for i, segment in enumerate(segments, 1):\n",
    "    print(f\"  [{i}/{len(segments)}] {segment}...\", end=' ')\n",
    "    \n",
    "    # Prepare transactions for this segment\n",
    "    transactions = prepare_transactions(\n",
    "        train_seg_enriched,\n",
    "        filter_column='segment',\n",
    "        filter_values=segment,\n",
    "        top_n_products=80\n",
    "    )\n",
    "    \n",
    "    # Generate rules\n",
    "    rules = generate_association_rules(\n",
    "        transactions,\n",
    "        min_support=0.005,\n",
    "        min_confidence=0.15,\n",
    "        min_lift=1.3,\n",
    "        max_transactions=100_000\n",
    "    )\n",
    "    \n",
    "    if rules is not None:\n",
    "        rules['segment'] = segment\n",
    "        all_seg_rules.append(rules)\n",
    "        print(f\"{len(rules)} rules\")\n",
    "    else:\n",
    "        print(\"No rules\")\n",
    "\n",
    "# Consolidate\n",
    "if all_seg_rules:\n",
    "    segment_rules = pd.concat(all_seg_rules, ignore_index=True)\n",
    "    segment_rules.to_csv('../data/processed/rules_by_segment.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nTotal rules by segment: {len(segment_rules):,}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nEvaluating rules by segment...\")\n",
    "    metrics_seg = evaluate_rules(\n",
    "        rules=segment_rules,\n",
    "        test_data=test_seg_enriched,\n",
    "        groupby_column='segment',\n",
    "        k=10\n",
    "    )\n",
    "    print_evaluation_results(metrics_seg)\n",
    "else:\n",
    "    print(\"No segment rules generated\")\n",
    "    metrics_seg = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68afc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# COMPARE RULES BETWEEN SEGMENTS\n",
    "\n",
    "print(\"Loading rules by segment...\")\n",
    "segment_rules = pd.read_csv('../data/processed/rules_by_segment.csv')\n",
    "\n",
    "print(f\"Total rules: {len(segment_rules):,}\")\n",
    "print(f\"Segments: {segment_rules['segment'].nunique()}\")\n",
    "\n",
    "# 1. CREATE RULE IDENTIFIER\n",
    "\n",
    "# Create unique rule identifier (antecedent -> consequent)\n",
    "segment_rules['rule_id'] = segment_rules['antecedent'] + ' -> ' + segment_rules['consequent']\n",
    "\n",
    "print(f\"\\nUnique rules (across all segments): {segment_rules['rule_id'].nunique()}\")\n",
    "\n",
    "# 2. RULES SHARED BETWEEN SEGMENTS\n",
    "\n",
    "# Count how many segments share each rule\n",
    "rule_counts = segment_rules.groupby('rule_id')['segment'].apply(lambda x: list(x)).reset_index()\n",
    "rule_counts['n_segments'] = rule_counts['segment'].apply(len)\n",
    "rule_counts['segments_list'] = rule_counts['segment'].apply(lambda x: ', '.join(sorted(x)))\n",
    "\n",
    "# Distribution\n",
    "print(\"\\nRule sharing distribution:\")\n",
    "sharing_dist = rule_counts['n_segments'].value_counts().sort_index()\n",
    "for n_seg, count in sharing_dist.items():\n",
    "    pct = count / len(rule_counts) * 100\n",
    "    print(f\"  Rules in {n_seg} segment(s): {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Unique vs shared\n",
    "unique_rules = rule_counts[rule_counts['n_segments'] == 1]\n",
    "shared_rules = rule_counts[rule_counts['n_segments'] > 1]\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Unique rules (1 segment only): {len(unique_rules)} ({len(unique_rules)/len(rule_counts)*100:.1f}%)\")\n",
    "print(f\"  Shared rules (2+ segments): {len(shared_rules)} ({len(shared_rules)/len(rule_counts)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "# 3. TOP SHARED RULES\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 20 MOST SHARED RULES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "most_shared = rule_counts.sort_values('n_segments', ascending=False).head(20)\n",
    "\n",
    "for idx, row in most_shared.iterrows():\n",
    "    print(f\"\\nRule: {row['rule_id']}\")\n",
    "    print(f\"  Shared by {row['n_segments']} segments: {row['segments_list']}\")\n",
    "\n",
    "\n",
    "# 4. UNIQUE RULES PER SEGMENT\n",
    "\n",
    "\n",
    "for seg in segments:\n",
    "    # Rules unique to this segment\n",
    "    seg_rules = set(segment_rules[segment_rules['segment'] == seg]['rule_id'])\n",
    "    \n",
    "    # Rules from other segments\n",
    "    other_rules = set(segment_rules[segment_rules['segment'] != seg]['rule_id'])\n",
    "    \n",
    "    # Unique rules\n",
    "    unique_to_seg = seg_rules - other_rules\n",
    "    \n",
    "    n_total = len(seg_rules)\n",
    "    n_unique = len(unique_to_seg)\n",
    "    pct_unique = (n_unique / n_total * 100) if n_total > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{seg}:\")\n",
    "    print(f\"  Total rules: {n_total}\")\n",
    "    print(f\"  Unique rules: {n_unique} ({pct_unique:.1f}%)\")\n",
    "    \n",
    "\n",
    "# 5. VISUALIZATION\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Rule sharing distribution\n",
    "ax1 = axes[0] \n",
    "sharing_dist.plot(kind='bar', ax=ax1, color='steelblue')\n",
    "ax1.set_xlabel('Number of segments sharing the rule')\n",
    "ax1.set_ylabel('Number of rules')\n",
    "ax1.set_title('Distribution of Rule Sharing')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Rules per segment (unique vs shared)\n",
    "ax2 = axes[1]\n",
    "seg_stats = []\n",
    "for seg in segments:\n",
    "    seg_rules = set(segment_rules[segment_rules['segment'] == seg]['rule_id'])\n",
    "    other_rules = set(segment_rules[segment_rules['segment'] != seg]['rule_id'])\n",
    "    unique = len(seg_rules - other_rules)\n",
    "    shared = len(seg_rules & other_rules)\n",
    "    seg_stats.append({'segment': seg, 'unique': unique, 'shared': shared})\n",
    "\n",
    "seg_stats_df = pd.DataFrame(seg_stats).set_index('segment')\n",
    "seg_stats_df.plot(kind='barh', stacked=True, ax=ax2, color=['steelblue', 'coral'])\n",
    "ax2.set_xlabel('Number of rules')\n",
    "ax2.set_title('Rules per Segment (Unique vs Shared)')\n",
    "ax2.legend(['Unique', 'Shared with other segments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of approaches\n",
    "\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Approach': 'By Department',\n",
    "        'Rules': len(dept_rules),\n",
    "        'Precision@10': f\"{metrics_dept['precision@K']:.2%}\",\n",
    "        'Recall@10': f\"{metrics_dept['recall@K']:.2%}\",\n",
    "        'Coverage': f\"{metrics_dept['coverage']:.2%}\",\n",
    "        'Avg Hits': f\"{metrics_dept['avg_hits']:.2f}\"\n",
    "    },\n",
    "    {\n",
    "        'Approach': 'Cross-Department',\n",
    "        'Rules': len(cross_rules) if cross_rules is not None else 0,\n",
    "        'Precision@10': f\"{metrics_cross['precision@K']:.2%}\" if metrics_cross else 'N/A',\n",
    "        'Recall@10': f\"{metrics_cross['recall@K']:.2%}\" if metrics_cross else 'N/A',\n",
    "        'Coverage': f\"{metrics_cross['coverage']:.2%}\" if metrics_cross else 'N/A',\n",
    "        'Avg Hits': f\"{metrics_cross['avg_hits']:.2f}\" if metrics_cross else 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'Approach': 'By Segment',\n",
    "        'Rules': len(segment_rules) if all_seg_rules else 0,\n",
    "        'Precision@10': f\"{metrics_seg['precision@K']:.2%}\" if metrics_seg else 'N/A',\n",
    "        'Recall@10': f\"{metrics_seg['recall@K']:.2%}\" if metrics_seg else 'N/A',\n",
    "        'Coverage': f\"{metrics_seg['coverage']:.2%}\" if metrics_seg else 'N/A',\n",
    "        'Avg Hits': f\"{metrics_seg['avg_hits']:.2f}\" if metrics_seg else 'N/A'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(comparison.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
